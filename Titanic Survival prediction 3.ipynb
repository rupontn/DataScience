{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing Necessary Libraries."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#data analysis libraries \nimport numpy as np\nimport pandas as pd\n\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now Read and Explore the data by using panda library function- read_csv() and explore()"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/titanic/test.csv\")\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\n# preview the data\ntrain.head()\n# check the number of missing values and other information in the feature\n#train.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# check the number of missing values and other information in the feature\ntrain.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Check the Information of Train and Test Data\ntrain.info()\nprint(\"----------------------------\")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Selecting Features and Data Engineering for Missing values in feature  :** Among the features 19.8% data is missing in age feature. 77.1% data are missing in cabin feature and 0.22% data is missing in embarked  feature. We will drop cabin feature considering it will be hard/incorrect to fill up this amount of missing data. In embarked feature we will fill the missing value by most appeared value in this feature. Also we will drop feature passenger id, Name and ticket considering as irreleveant feauture. "},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping unnecessary columns\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the Information of Train and Test Data\ntrain.info()\nprint(\"----------------------------\")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping unnecessary columns\ntrain = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\ntrain = train.drop(['PassengerId'], axis = 1)\ntest = test.drop(['PassengerId'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the Information of Train and Test Data\ntrain.info()\nprint(\"----------------------------\")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will fill up the Embarked feature with the most occured value which is \"S\" and We will fill up the missing age value by generating random number within standard deviation from mean value in the age feature. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the Information of Train and Test Data\ntrain.info()\nprint(\"----------------------------\")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get average, std, and number of NaN values in titanic_df\naverage_age_train   = train[\"Age\"].mean()\nstd_age_train       = train[\"Age\"].std()\ncount_nan_train = train[\"Age\"].isnull().sum()\n\n# get average, std, and number of NaN values in test_df\naverage_age_test   = test[\"Age\"].mean()\nstd_age_test       = test[\"Age\"].std()\ncount_nan_test = test[\"Age\"].isnull().sum()\n\n# generate random numbers between (mean - std) & (mean + std)\nrand_1 = np.random.randint(average_age_train - std_age_train, average_age_train + std_age_train, size = count_nan_train)\nrand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_test)\n\nprint(average_age_train)\n#train[\"Age\"]=train[\"Age\"].dropna()\n# fill NaN values in Age column with random values generated\ntrain[\"Age\"][np.isnan(train[\"Age\"])] = rand_1\ntest[\"Age\"][np.isnan(test[\"Age\"])] = rand_2\n\n# convert from float to int\ntrain['Age'] = train['Age'].astype(int)\ntest['Age']    = test['Age'].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the Information of Train and Test Data\ntrain.info()\nprint(\"----------------------------\")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Family\n\n# Instead of having two columns Parch & SibSp, \n# we can have only one column represent if the passenger had any family member aboard or not,\n# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n\ntrain['Family'] =  train[\"Parch\"] + train[\"SibSp\"]\ntrain['Family'].loc[train['Family'] > 0] = 1\ntrain['Family'].loc[train['Family'] == 0] = 0\n\ntest['Family'] =  test[\"Parch\"] + test[\"SibSp\"]\ntest['Family'].loc[test['Family'] > 0] = 1\ntest['Family'].loc[test['Family'] == 0] = 0\n\n#titanic_df = titanic_df.drop(['SibSp','Parch'], axis=1)\n#test_df    = test_df.drop(['SibSp','Parch'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the Information of Train and Test Data\ntrain.info()\nprint(\"----------------------------\")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Visualization:**\nAnalysis of features by using data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train)\n\n#print percentages of females vs. males that survive\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw a bar plot of survival by Embarked station\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw a histogram plot of \ntrain['Age'].hist(bins=70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw a bar plot of survival by Family\nsns.barplot(x=\"Family\", y=\"Survived\", data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Managing the Categorical data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"labelencoder_train_sex= LabelEncoder()\ntrain['Sex']= labelencoder_train_sex.fit_transform(train['Sex'])\nlabelencoder_test_sex= LabelEncoder()\ntest['Sex']= labelencoder_test_sex.fit_transform(test['Sex'])\n\nlabelencoder_train_embarked= LabelEncoder()\ntrain['Embarked']= labelencoder_train_embarked.fit_transform(train['Embarked'])\nlabelencoder_test_embarked= LabelEncoder()\ntest['Embarked']= labelencoder_test_embarked.fit_transform(test['Embarked'])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the Information of Train and Test Data\ntrain.info()\nprint(\"----------------------------\")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"average_Fare_test   = test[\"Fare\"].mean()\ntest[\"Fare\"][np.isnan(test[\"Fare\"])] = average_Fare_test\n\n# convert Fare from float to int\ntrain['Fare'] = train['Fare'].astype(int)\ntest['Fare']    = test['Fare'].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the Information of Train and Test Data\ntrain.info()\nprint(\"----------------------------\")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Classifier Comparison**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define training and testing sets\n\nX_train = train.drop(\"Survived\",axis=1)\nY_train = train[\"Survived\"]\nX_test  = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nlogreg.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machines\n\n svc = SVC()\n\n svc.fit(X_train, Y_train)\n\n Y_pred = svc.predict(X_test)\n\n svc.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" knn = KNeighborsClassifier(n_neighbors = 3)\n\n knn.fit(X_train, Y_train)\n\n Y_pred = knn.predict(X_test)\n\n knn.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\n\n gaussian = GaussianNB()\n\n gaussian.fit(X_train, Y_train)\n\n Y_pred = gaussian.predict(X_test)\n\n gaussian.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"               **Classifier** \t  **Accuracy**\n        Logistic Regression\t       80.24%\n               SVM\t               90.12%\n          Random Forest\t           96.96%\n       K Nearest Neighbour\t       84.06%\n       Gaussian Na√Øve bayes\t       79.01%\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('titanic.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}